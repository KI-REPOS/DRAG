# ğŸ¤– RAG Pipeline â€” Retrieval-Augmented Generation (ChromaDB + Flask)

A **Flask-based RAG system** where users can upload **files** (`PDF, DOCX, PPT, TXT, PNG, JPEG`) or provide **URLs** (websites, YouTube videos).  
Data is **converted into vector embeddings**, stored in **ChromaDB**, and queried through a clean web interface.  
Retrieved chunks are polished by the **Phi-2 Quantized Model** before being presented to the user.

---

## ğŸš€ Features

- ğŸ“‚ **Multi-format ingestion** â€” PDF, DOCX, PPT, TXT, PNG, JPEG  
- ğŸŒ **Web & YouTube support** â€” fetch website content & video transcripts  
- âœ‚ï¸ **Chunk-based embeddings** â€” improves retrieval quality  
- ğŸ§  **ChromaDB integration** â€” efficient similarity search  
- ğŸ’» **Flask Web UI** â€” clean query interface  
- ğŸ” **Top-k retrieval** â€” fetches the most relevant chunks only  
- ğŸ¯ **LLM Polishing** â€” refined answers using **Phi-2 (quantized)**  
- âš¡ **Two-step execution** â€” `ingest_data.py` (indexing) â†’ `app.py` (querying)  

---

## ğŸ“‚ Use Cases

- ğŸ“ **Custom Q&A Chatbot** over private documents  
- ğŸ“ **Research assistant** for papers, slides, & YouTube lectures  
- ğŸ¢ **Enterprise knowledge base** with internal reports  
- ğŸ“– **Summarizer** for articles, PDFs, and videos  

---

## ğŸ› ï¸ Installation & Setup

<details>
<summary>ğŸ“¦ Step 1 â€” Clone the repository</summary>

```
git clone https://github.com/your-username/rag-pipeline.git
cd rag-pipeline
```
</details> <details> <summary>ğŸ Step 2 â€” Create & activate virtual environment</summary>

```
# Create virtual environment
py -3.12 -m venv venv

# Windows
venv\Scripts\activate

# macOS / Linux
source venv/bin/activate
```
</details> <details> <summary>âš™ï¸ Step 3 â€” Install dependencies</summary>

```
pip install -r requirements.txt
```
</details> <details> <summary>ğŸ§  Step 4 â€” Download the Phi-2 Model</summary>

- The Phi2Q_4_k.ggfu model (~1.66 GB) is not included in the repository.

ğŸ‘‰ [Download here](https://huggingface.co/TheBloke/phi-2-GGUF/resolve/main/phi-2.Q4_K_M.gguf)

- Place the file in the models/ directory.

</details>

â–¶ï¸ **Execution**

<details> <summary>ğŸ“¥ Step 1 â€” Ingest & Index Data</summary>

Run to create vector embeddings/chunks and store them in ChromaDB:
```
python ingest_data.py
```

- âœ… Converts files/URLs into chunks
- âœ… Creates embeddings
- âœ… Stores vectors in ChromaDB

</details> <details> <summary>ğŸ’¡ Step 2 â€” Run the Flask Web App</summary>
python app.py


- âœ… Starts server at http://0.0.0.0:5000
- âœ… Upload more files / paste URLs
- âœ… Ask questions & get AI-polished results

</details>
